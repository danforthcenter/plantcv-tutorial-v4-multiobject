{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Welcome to the Multi Object or Multi Leaf Tutorial\n",
    "Made by: Katie Murphy\n",
    "Updated: May 16, 2023\n",
    "\n",
    "Updated August 16, 2023 by Haley Schuhl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install PlantCV and required dependencies\n",
    "%pip install \"altair>=5\" ipympl plantcv\n",
    "\n",
    "# Give access and mount your Google Drive (need a Google Account)\n",
    "# Change path to directory you wish output files to be saved to.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Enable widget feature with matplotlib\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "#View working directory, may need to change path\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "604065b5"
   },
   "source": [
    "# Section 1: Importing Image and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary Python packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the notebook display method\n",
    "# If widget is not working, then change to inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62ef791b"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from plantcv import plantcv as pcv\n",
    "from plantcv.parallel import WorkflowInputs\n",
    "\n",
    "# Print out the version of PlantCV being used by the Jupyter kernel\n",
    "pcv.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, initialize your workflow inputs. It's possible to just directly read a sample image, but this step sets up a workflow to be used later in batch processing/running in parallel. Remember, always keep your raw images separate from your newly processed images! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4468af74"
   },
   "source": [
    "## Input/Output variables\n",
    "\n",
    "The options class mimics the workflow command-line argument parser that is used for workflow parallelization. Using it while developing a workflow in Jupyter makes it easier to convert the workflow to a script later. Remember, always keep your raw images separate from your newly processed images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input/output options\n",
    "args = WorkflowInputs(\n",
    "    images=[\"./imgs/O_HLP_1_P_LEAF_2022-12-07_09_32_15.jpg\"],\n",
    "    names=\"image1\",\n",
    "    result=\"example_results_oneimage_file.json\",\n",
    "    outdir=\".\",\n",
    "    writeimg=False,\n",
    "    debug=\"plot\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug\n",
    "# Change display settings\n",
    "pcv.params.dpi = 100\n",
    "pcv.params.text_size = 20\n",
    "pcv.params.text_thickness = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "343a0816"
   },
   "source": [
    "## Read the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnZYaudIgcHd"
   },
   "source": [
    "### Google Colaboratory Users:\n",
    "If you are running this notebook using Google Colaboratory, you will need to use the cell below to complete the tutorial unless you cloned the repository from GitHub to your personal Google Drive account. Once you begin developing your workflow for your data, you can delete this text cell and the code cell below so you avoid any conflicts the next time you use this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ItGZYvOyOir"
   },
   "outputs": [],
   "source": [
    "img = pcv.io.open_url(url=\"https://github.com/danforthcenter/plantcv-tutorial-v4-multiobject/blob/main/imgs/O_HLP_1_P_LEAF_2022-12-07_09:32:15.jpg?raw=true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8URuV3ZhALj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Local system use:\n",
    "If you have downloaded this notebook or the repository to your local device, then you will need to use the cell below to bring your image into the notebook. Do not run this line if you are navigating through the **tutorial** using Google Colaboratory.\n",
    "\n",
    "NOTE: *If you are developing your own workflow using this notebook, make sure you remove the code cell above with the URL and uncomment (remove the hashtag [#] to make the code active. This will call the image you defined during the Inputs/Outputs step.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4Na59TNNg1x"
   },
   "source": [
    "### Reading images into your environment using *pcv.readimage()*\n",
    "Inputs:\n",
    "   * filename = Image file to be read in\n",
    "   * mode     = How the image will be read into the notebook; either 'native' (default), 'rgb', 'gray', 'csv', or 'envi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, path, filename = pcv.readimage(filename=args.image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crop image if necessary. This is optional. \n",
    "crop_img = pcv.crop(img=img, x=0, y=0, h=3500, w=4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If your image is not straight, rotate it. Here our image is straight becasue our camera was \n",
    "# on a flat surface, so we will rotate 0 degrees (unchanged). \n",
    "\n",
    "rotate_img = pcv.transform.rotate(crop_img, 0, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#First, find the color card. \n",
    "card_mask = pcv.transform.detect_color_card(rgb_img=rotate_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a color card matrix \n",
    "\n",
    "headers, card_matrix = pcv.transform.get_color_matrix(rgb_img=rotate_img, mask=card_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the standard color card matrix, we know what the colors of those chips should be in an \"ideal\" image, \n",
    "# so we will correct to those values as the TARGET c\n",
    "# Look at where your white chip is in the image to determine which position your card is in (pos)\n",
    "# This function is undergoing development and will eventually be deprecated to make color card segmentation simpler\n",
    "# Position 3 is the only value that will yield a color corrected image\n",
    "\n",
    "std_color_matrix = pcv.transform.std_color_matrix (pos=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Color correct your image to the standard values\n",
    "# look at the image - does the color look good? \n",
    "# If it looks crazy, you probably don't have the card found well and need to go back and \n",
    "# define the start and spacing for the card\n",
    "\n",
    "img_cc = pcv.transform.affine_color_correction(rgb_img=rotate_img, source_matrix=card_matrix, \n",
    "                                               target_matrix=std_color_matrix)\n",
    "pcv.plot_image(img_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update params related to plotting so we can see better \n",
    "pcv.params.text_size=50\n",
    "pcv.params.text_thickness=25\n",
    "\n",
    "\n",
    "#Look at the colorspace - which of these looks the best for masking? \n",
    "# Which channel makes the plant look most distinct from the background?\n",
    "colorspace_img = pcv.visualize.colorspaces(rgb_img=img_cc, original_img=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If you want to save your color corrected image, do so here. Do NOT save over your raw image. \n",
    "# We are saving as a temporary image here becasue we want to use it for thresholding. \n",
    "\n",
    "pcv.print_image(img_cc, filename = \"./color_corrected_img_temp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize all the colors to make decisions on how to threshold. I picked the two channels from the colorspace above that looked distinct\n",
    "\n",
    "color_scatter = pcv.visualize.pixel_scatter_plot(paths_to_imgs=[\"./color_corrected_img_temp.png\"], \n",
    "                                                 x_channel = \"a\", y_channel =\"b\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Threshold your image by choosing points in the plot that will separate the green plant pixels from everything else. \n",
    "# It will draw a line between your two points and take every pixel \"above\" (if set to true). Do you get all of the plant?\n",
    "\n",
    "thresh1 = pcv.threshold.dual_channels(rgb_img = img_cc, x_channel = \"a\", y_channel = \"b\", \n",
    "                                      points = [(100,120),(130,160)], above=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in small objects if below the \"size\" threshold\n",
    "a_fill_image = pcv.fill(bin_img=thresh1, size=50)\n",
    "# Flood fill any holes in the leaves (false negative pixels)\n",
    "a_fill_image = pcv.fill_holes(a_fill_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the region of interest (ROI). \n",
    "# This should include  all of your leaves or all of your plants, but not you color card or other noise. \n",
    "\n",
    "roi1 = pcv.roi.rectangle(img=img_cc, x=0, y=0, h=3300, w=3800)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a new filtered mask that only keeps the leaves in your ROI and not objects outside of the ROI\n",
    "# We have set to partial here so that if a leaf extends outside of your ROI it will still be selected. Switch to \"cutto\" if you have other plants that are getting selected on accident\n",
    "\n",
    "# Inputs:\n",
    "#    mask            = the clean mask you made above\n",
    "#    roi            = the region of interest you specified above\n",
    "#    roi_type       = 'partial' (default, for partially inside the ROI), 'cutto', or \n",
    "#                     'largest' (keep only largest contour)\n",
    "\n",
    "kept_mask  = pcv.roi.filter(mask=a_fill_image, roi=roi1, roi_type='partial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Label the objects in your region of interest and number them\n",
    "#Each object should be a different color. If your objects are the same color and/or are touching, go back to your mask so that they are separate or it will treat them as a single object\n",
    "\n",
    "#    mask            = the clean mask you made above after making your ROI\n",
    "\n",
    "labeled_objects, n_obj = pcv.create_labels(mask=kept_mask)\n",
    "\n",
    "# This example has one color per leaf, so this would be good enough to do per-replicate trait extraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pcv.Points() to gather center coordinates of ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are multiple ways to get your leaves. If you are finding this single, large ROI is not getting your plants individually, try another method.  Here, we will use the interactive tool to click on locations to make ROIs. This is a good method if you cannot get a clean ROI using single or multi. This method cannot be run in paralell, only in a jupyter notebook, because you cannot \"interact\" in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collect points for center of ROIs by clicking on each leaf. \n",
    "marker = pcv.Points(img_cc, figsize=(8,8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create ROIs based on the selected points\n",
    "# Your ROIs will show up as blue circles here. \n",
    "roi2 = pcv.roi.multi(img=img_cc, coord=marker.points, radius=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label the objects in your region of interest and number them\n",
    "# Each object should be a different color. If your objects are the same color and/or are touching, go back to your mask \n",
    "# so that they are separate or it will treat them as a single object\n",
    "\n",
    "\n",
    "labeled_objects2, n_obj2 = pcv.create_labels(mask=a_fill_image, rois=roi2, roi_type=\"partial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############### Analysis ################ \n",
    "  \n",
    "# Find shape properties, data gets stored to an Outputs class automatically\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   labeled_mask - the mask of each individual object, set by the create_labels function. \n",
    "#   n_labels - the number of objects, set by the create_labels function. \n",
    "\n",
    "analysis_image = pcv.analyze.size(img=img_cc, labeled_mask=labeled_objects, n_labels=n_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine color properties: Histograms, Color Slices and Pseudocolored Images, output color analyzed images (optional)\n",
    "\n",
    "\n",
    "color_histogram = pcv.analyze.color(rgb_img=img_cc, labeled_mask=labeled_objects, n_labels=n_obj, colorspaces='hsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The save results function will take the measurements stored when running any PlantCV analysis functions, format, \n",
    "# and print an output text file for data analysis. The Outputs class stores data whenever any of the following functions\n",
    "# are ran: pcv.analyze.bound_horizontal, pcv.analyze.bound_vertical, pcv.analyze.color, pcv.analyze.grayscale, pcv.analyze.size, \n",
    "# pcv.analyze.yii, pcv.report_size_marker_area, pcv.watershed_segmentation. If no functions have been run, it will print an empty text file \n",
    "\n",
    "#This saves results for one image, and each image is saved individually if you run another image (it will overwrite the last one)\n",
    "pcv.outputs.save_results(filename=args.result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
